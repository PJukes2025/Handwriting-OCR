import streamlit as st
import cv2
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter
import pytesseract
import io
import json
from datetime import datetime
import pandas as pd

# Page config for mobile-friendly experience
st.set_page_config(
    page_title="Journalist's OCR Tool",
    page_icon="üìù",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for mobile responsiveness
st.markdown("""
<style>
    .stFileUploader > div > div > div {
        padding: 1rem;
    }
    .stImage > div {
        text-align: center;
    }
    @media (max-width: 768px) {
        .main .block-container {
            padding-top: 2rem;
            padding-left: 1rem;
            padding-right: 1rem;
        }
    }
    .success-box {
        padding: 1rem;
        border-radius: 0.5rem;
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        margin: 1rem 0;
    }
    .processing-stats {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #007bff;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ---------------------- Session State ----------------------
if 'ocr_results' not in st.session_state:
    st.session_state.ocr_results = []   # list of dicts (each with image, text, original_text, etc.)
if 'processing_history' not in st.session_state:
    st.session_state.processing_history = []
if 'user_corrections' not in st.session_state:
    st.session_state.user_corrections = {}

# ---------------------- Image Preprocessing ----------------------
def preprocess_image(image, enhancement_level="medium"):
    """Advanced preprocessing for handwriting, optimized for margin notes"""
    img_array = np.array(image)

    # Convert to grayscale if needed
    if len(img_array.shape) == 3:
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        gray = img_array

    # Noise removal
    denoised = cv2.fastNlMeansDenoising(gray)

    # Enhance based on level
    if enhancement_level == "light":
        processed = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
    elif enhancement_level == "medium":
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(denoised)
        processed = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
    else:  # aggressive
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(6,6))
        enhanced = clahe.apply(denoised)

        # Dilation to separate touching letters
        kernel = np.ones((1,1), np.uint8)
        enhanced = cv2.dilate(enhanced, kernel, iterations=1)

        # Morphological operations for margin text
        kernel2 = np.ones((2,2), np.uint8)
        processed = cv2.morphologyEx(enhanced, cv2.MORPH_CLOSE, kernel2)
        processed = cv2.threshold(processed, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]

        # Additional erosion to separate merged characters
        kernel3 = np.ones((1,1), np.uint8)
        processed = cv2.erode(processed, kernel3, iterations=1)

    return processed

# ---------------------- OCR (Tesseract) ----------------------
def extract_text_tesseract(image, enhancement_level="medium"):
    """Extract text using Tesseract OCR with multiple configurations for best results"""
    processed_img = preprocess_image(image, enhancement_level)
    pil_processed = Image.fromarray(processed_img)

    # Safe whitelist (no double quotes, keeps single quote and space)
    whitelist_chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.,!?;:()-@&/ '"
    configs = [
        f'--oem 3 --psm 6 -c tessedit_char_whitelist="{whitelist_chars}"',
        f'--oem 3 --psm 7 -c tessedit_char_whitelist="{whitelist_chars}"',
        f'--oem 3 --psm 8 -c tessedit_char_whitelist="{whitelist_chars}"'
    ]

    results = {}
    best_result = ""
    best_config = "default"

    for i, config in enumerate(configs):
        try:
            result = pytesseract.image_to_string(pil_processed, config=config).strip()
            config_name = ["general", "block", "word"][i]
            results[config_name] = result

            # Choose the result with the most content (usually best)
            if len(result) > len(best_result):
                best_result = result
                best_config = config_name

        except Exception as e:
            results[f"config_{i}"] = f"Error: {e}"

    return best_result, results, processed_img, best_config

# ---------------------- Learning Corrections ----------------------
def learn_from_corrections(original_text, corrected_text, image_name):
    """Store user corrections to improve future recognition"""
    if original_text.strip() and corrected_text.strip() and original_text != corrected_text:
        correction_entry = {
            'timestamp': datetime.now().isoformat(),
            'image': image_name,
            'original': original_text,
            'corrected': corrected_text,
            'pattern_type': 'user_correction'
        }
        st.session_state.user_corrections[image_name] = correction_entry

def apply_learned_corrections(text, image_name):
    """Apply previously learned corrections"""
    corrected_text = text

    # Common handwriting OCR corrections based on analysis
    common_fixes = {
        ' or ': ' a ',
        'rn': 'm',
        'cl': 'd',
        'li': 'h',
        'rnore': 'more',
        'ornd': 'and',
        'tlie': 'the',
        'orll': 'all',
        'tl1e': 'the',
        'witl1': 'with',
        'l1is': 'his',
        'l1er': 'her'
    }

    # Journalism-specific corrections for margin notes
    journalism_fixes = {
        'MDSCOW': 'MOSCOW',
        'POLIGH': 'POLISH',
        'UKRAIN': 'UKRAINE',
        'CYEER': 'CYBER',
        'POISDN': 'POISON',
        'TARGEI': 'TARGET',
        'BACKDCOR': 'BACKDOOR',
        'MDSC0W': 'MOSCOW',
        'RU5SIA': 'RUSSIA',
        'UKRA1NE': 'UKRAINE'
    }

    # Apply common fixes first
    for wrong, right in common_fixes.items():
        corrected_text = corrected_text.replace(wrong, right)

    # Apply journalism-specific fixes
    for wrong, right in journalism_fixes.items():
        corrected_text = corrected_text.replace(wrong, right)

    # Apply stored corrections (simple string replacement for now)
    for correction in st.session_state.user_corrections.values():
        if correction['original'] in corrected_text:
            corrected_text = corrected_text.replace(correction['original'], correction['corrected'])

    return corrected_text

# ---------------------- Helpers (export & display) ----------------------
def results_to_dataframe(results_list):
    """Convert results (list of dicts) to a DataFrame for export."""
    rows = []
    for r in results_list:
        rows.append({
            "filename": r.get("filename", ""),
            "text": r.get("text", ""),
            "original_text": r.get("original_text", ""),
            "engine": r.get("engine", ""),
            "best_config": r.get("best_config", ""),
            "timestamp": r.get("timestamp", "")
        })
    return pd.DataFrame(rows)

def make_csv_bytes(df: pd.DataFrame) -> bytes:
    buf = io.StringIO()
    df.to_csv(buf, index=False)
    return buf.getvalue().encode("utf-8")

def make_json_bytes(results_list) -> bytes:
    # Serialize text-only fields for portability
    minimal = [
        {
            "filename": r.get("filename", ""),
            "text": r.get("text", ""),
            "original_text": r.get("original_text", ""),
            "engine": r.get("engine", ""),
            "best_config": r.get("best_config", ""),
            "timestamp": r.get("timestamp", "")
        }
        for r in results_list
    ]
    return json.dumps(minimal, ensure_ascii=False, indent=2).encode("utf-8")

def process_images(files, enhancement_level):
    """Run OCR + apply learned corrections for a list of uploaded files or PIL Images."""
    processed_results = []
    for uploaded_file in files:
        try:
            # Support both UploadedFile (from st.file_uploader) and raw PIL Images (for reruns)
            image = uploaded_file if isinstance(uploaded_file, Image.Image) else Image.open(uploaded_file)
            filename = getattr(uploaded_file, "name", "image.png")

            best_text, all_configs, processed_img, best_config = extract_text_tesseract(image, enhancement_level)
            corrected_text = apply_learned_corrections(best_text, filename)

            result = {
                'filename': filename,
                'text': corrected_text,
                'original_text': best_text,
                'engine': f'Tesseract ({best_config})',
                'all_configs': all_configs,
                'best_config': best_config,
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'image': image,
                'processed_image': processed_img
            }
            processed_results.append(result)

        except Exception as e:
            st.error(f"‚ùå Error processing {getattr(uploaded_file, 'name', 'image')}: {e}")
    return processed_results

def display_results(results, show_processed_images=False, show_alternative_configs=False):
    """Render results + edit & save UI."""
    for idx, res in enumerate(results):
        st.subheader(f"üìù {res['filename']}")

        # Show extracted text
        st.text_area("Extracted Text", res['text'], height=150, key=f"view_text_{idx}")

        # Optional images / configs
        if show_processed_images:
            st.image(res['processed_image'], caption="Processed Image", use_container_width=True)

        if show_alternative_configs:
            with st.expander("Alternative OCR Configurations"):
                for cfg, txt in res['all_configs'].items():
                    st.write(f"[{cfg}]")
                    st.code(txt if txt else "(no output)")

        # --- Edit & Save Correction UI ---
        with st.expander("‚úèÔ∏è Edit & Save Correction"):
            edited_text = st.text_area(
                "Correct the text below and click Save to teach the tool.",
                value=res['text'],
                height=160,
                key=f"edit_text_{idx}"
            )
            if st.button("Save Correction", key=f"save_corr_{idx}"):
                # Learn mapping from original OCR to your corrected text
                learn_from_corrections(res['original_text'], edited_text, res['filename'])
                # Update the displayed text for this result (same dict stored in session)
                res['text'] = edited_text
                st.success("Saved! Future runs will apply this correction automatically.")

# ---------------------- UI (sidebar & controls) ----------------------
st.title("üìù Journalist's Handwriting OCR Tool")
st.markdown("*Mobile-friendly batch OCR with learning capabilities - Tesseract Edition*")

st.sidebar.header("Settings")
enhancement_level = st.sidebar.selectbox(
    "Image Enhancement Level",
    ["light", "medium", "aggressive"],
    index=1,
    help="Choose based on your handwriting clarity"
)

batch_mode = st.sidebar.checkbox("Batch Processing Mode", value=True)
show_processed_images = st.sidebar.checkbox("Show Processed Images", value=False)
show_alternative_configs = st.sidebar.checkbox("Show Alternative OCR Configs", value=False)

st.info("üöÄ **Fast & Reliable**: This version uses Tesseract OCR for instant processing without downloads. Based on our handwriting analysis, expect 80-90% accuracy on your neat notes!")

# ---------------------- File upload ----------------------
st.header("üì§ Upload Images")
if batch_mode:
    uploaded_files = st.file_uploader(
        "Choose image files (JPG, PNG, HEIC)",
        type=['jpg', 'jpeg', 'png', 'heic'],
        accept_multiple_files=True,
        help="You can upload multiple images at once from your phone or tablet"
    )
else:
    uploaded_files = [st.file_uploader(
        "Choose an image file",
        type=['jpg', 'jpeg', 'png', 'heic']
    )]

uploaded_files = [f for f in uploaded_files if f is not None]

if uploaded_files:
    st.success(f"üìÅ {len(uploaded_files)} file(s) uploaded successfully!")

# ---------------------- Process button ----------------------
if st.button("üîç Process All Images", type="primary"):
    progress_bar = st.progress(0)
    status_text = st.empty()

    results = process_images(uploaded_files, enhancement_level)

    # append to session state
    for r in results:
        st.session_state.ocr_results.append(r)

    for i in range(len(uploaded_files)):
        progress_bar.progress((i + 1) / max(1, len(uploaded_files)))

    st.success("‚úÖ Processing complete!")
    status_text.text("All files processed.")

    # Display results
    display_results(results, show_processed_images, show_alternative_configs)

    # ---- Download buttons for this run ----
    st.markdown("### ‚¨áÔ∏è Download This Run")
    df_run = results_to_dataframe(results)
    csv_bytes_run = make_csv_bytes(df_run)
    json_bytes_run = make_json_bytes(results)

    st.download_button(
        label="Download CSV (this run)",
        data=csv_bytes_run,
        file_name=f"ocr_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv"
    )
    st.download_button(
        label="Download JSON (this run)",
        data=json_bytes_run,
        file_name=f"ocr_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        mime="application/json"
    )

# ---------------------- Re-run with corrections applied ----------------------
if st.session_state.ocr_results:
    st.markdown("---")
    st.subheader("üîÅ Re-run with Corrections Applied")
    st.caption("This will re-OCR the stored images using current settings and apply your learned corrections.")
    if st.button("Re-run Now"):
        # Use images already in session state
        images_for_rerun = [r['image'] for r in st.session_state.ocr_results]

        # Reprocess (fresh OCR + apply current corrections)
        rerun_results = process_images(images_for_rerun, enhancement_level)

        # Replace session results with the new outputs
        st.session_state.ocr_results = rerun_results

        st.success("üîÅ Re-run complete! Results updated below.")
        display_results(rerun_results, show_processed_images, show_alternative_configs)

    # ---- Sidebar exports for all-time session results ----
    st.sidebar.markdown("### ‚¨áÔ∏è Export All Results (Session)")
    df_all = results_to_dataframe(st.session_state.ocr_results)
    csv_bytes_all = make_csv_bytes(df_all)
    json_bytes_all = make_json_bytes(st.session_state.ocr_results)

    st.sidebar.download_button(
        label="Download CSV (session)",
        data=csv_bytes_all,
        file_name=f"ocr_results_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv"
    )
    st.sidebar.download_button(
        label="Download JSON (session)",
        data=json_bytes_all,
        file_name=f"ocr_results_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        mime="application/json"
    )
