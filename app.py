import streamlit as st
import cv2
import numpy as np
from PIL import Image, ImageOps
import pytesseract
import json
from datetime import datetime
import pandas as pd
import hashlib
import io

# Page config

st.set_page_config(
page_title=â€œJournalistâ€™s OCR Toolâ€,
page_icon=â€œğŸ“â€,
layout=â€œwideâ€
)

# Initialize session state - SIMPLIFIED

if â€œocr_resultsâ€ not in st.session_state:
st.session_state.ocr_results = []

if â€œcorrectionsâ€ not in st.session_state:
st.session_state.corrections = {}

if â€œlearned_patternsâ€ not in st.session_state:
st.session_state.learned_patterns = {}

# Helper functions

def make_image_key(filename, image):
â€œâ€â€œCreate a unique key for this imageâ€â€â€
img_data = io.BytesIO()
image.save(img_data, format=â€˜PNGâ€™)
hash_val = hashlib.md5(img_data.getvalue()).hexdigest()[:8]
return fâ€{filename}_{hash_val}â€

def save_correction(image_key, original_text, corrected_text):
â€œâ€â€œSave a correction and learn from itâ€â€â€
if original_text == corrected_text:
return False

```
# Save the correction
st.session_state.corrections[image_key] = {
    "original": original_text,
    "corrected": corrected_text,
    "timestamp": datetime.now().isoformat()
}

# Learn patterns from the correction
learn_from_correction(original_text, corrected_text)
return True
```

def learn_from_correction(original, corrected):
â€œâ€â€œExtract learning patterns from a correctionâ€â€â€
if not original or not corrected or original == corrected:
return

```
# Word-level learning (most reliable)
orig_words = original.split()
corr_words = corrected.split()

# Simple word-by-word mapping
if len(orig_words) == len(corr_words):
    for orig_word, corr_word in zip(orig_words, corr_words):
        if orig_word != corr_word and len(orig_word) > 1:
            if orig_word not in st.session_state.learned_patterns:
                st.session_state.learned_patterns[orig_word] = {
                    "replacement": corr_word,
                    "count": 1,
                    "examples": [{"original": original, "corrected": corrected}]
                }
            else:
                # Update existing pattern
                st.session_state.learned_patterns[orig_word]["count"] += 1
                st.session_state.learned_patterns[orig_word]["replacement"] = corr_word

# Character-level patterns for single substitutions
if abs(len(original) - len(corrected)) <= 1:
    # Look for common OCR error patterns
    if "or" in original and "a" in corrected:
        pattern = "or"
        if pattern not in st.session_state.learned_patterns:
            st.session_state.learned_patterns[pattern] = {
                "replacement": "a",
                "count": 1,
                "examples": [{"original": original, "corrected": corrected}]
            }
        else:
            st.session_state.learned_patterns[pattern]["count"] += 1
```

def apply_learned_corrections(text, image_key):
â€œâ€â€œApply learned corrections to textâ€â€â€
# Check for direct override first
if image_key in st.session_state.corrections:
return st.session_state.corrections[image_key][â€œcorrectedâ€]

```
corrected_text = text

# Apply built-in fixes
built_in_fixes = {
    ' or ': ' a ',
    'rn': 'm', 
    'cl': 'd',
    'li': 'h',
    'tlie': 'the',
    'ornd': 'and',
    'MDSCOW': 'MOSCOW',
    'RUSSI': 'RUSSIA',
    'CYEER': 'CYBER'
}

for wrong, right in built_in_fixes.items():
    corrected_text = corrected_text.replace(wrong, right)

# Apply learned patterns (sort by count - most frequent first)
sorted_patterns = sorted(st.session_state.learned_patterns.items(), 
                       key=lambda x: -x[1]["count"])

for pattern, info in sorted_patterns:
    replacement = info["replacement"]
    if pattern in corrected_text:
        corrected_text = corrected_text.replace(pattern, replacement)

return corrected_text
```

def preprocess_image(image, enhancement_level=â€œmediumâ€):
â€œâ€â€œPreprocess image for OCRâ€â€â€
img_array = np.array(image)
if len(img_array.shape) == 3:
gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
else:
gray = img_array

```
denoised = cv2.fastNlMeansDenoising(gray)

if enhancement_level == "light":
    processed = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
elif enhancement_level == "medium":
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(denoised)
    processed = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
else:  # aggressive
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(6,6))
    enhanced = clahe.apply(denoised)
    kernel = np.ones((2,2), np.uint8)
    processed = cv2.morphologyEx(enhanced, cv2.MORPH_CLOSE, kernel)
    processed = cv2.threshold(processed, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]

return processed
```

def extract_text(image, enhancement_level=â€œmediumâ€):
â€œâ€â€œExtract text using Tesseract with multiple configurationsâ€â€â€
processed_img = preprocess_image(image, enhancement_level)
pil_processed = Image.fromarray(processed_img)

```
configs = [
    '--oem 3 --psm 6',
    '--oem 3 --psm 7',
    '--oem 3 --psm 8'
]

best_result = ""
best_config = "default"

for i, config in enumerate(configs):
    try:
        result = pytesseract.image_to_string(pil_processed, config=config).strip()
        config_name = ["general", "block", "word"][i]
        
        if len(result) > len(best_result):
            best_result = result
            best_config = config_name
    except Exception:
        continue

return best_result, processed_img, best_config
```

# Sidebar

st.sidebar.header(â€œSettingsâ€)
enhancement_level = st.sidebar.selectbox(
â€œEnhancement Levelâ€,
[â€œlightâ€, â€œmediumâ€, â€œaggressiveâ€],
index=1
)

st.sidebar.markdown(â€### ğŸ§  Learning Statusâ€)
num_corrections = len(st.session_state.corrections)
num_patterns = len(st.session_state.learned_patterns)

st.sidebar.metric(â€œSaved Correctionsâ€, num_corrections)
st.sidebar.metric(â€œLearned Patternsâ€, num_patterns)

if st.session_state.learned_patterns:
st.sidebar.markdown(â€**Top Learned Patterns:**â€)
sorted_patterns = sorted(st.session_state.learned_patterns.items(),
key=lambda x: -x[1][â€œcountâ€])[:5]
for pattern, info in sorted_patterns:
count = info[â€œcountâ€]
replacement = info[â€œreplacementâ€]
st.sidebar.caption(fâ€™â€{pattern}â€ â†’ â€œ{replacement}â€ ({count}x)â€™)

# Main interface

st.title(â€œğŸ“ Journalistâ€™s OCR Toolâ€)
st.markdown(â€*Simple learning OCR - gets smarter with each correction!*â€)

# File upload

uploaded_files = st.file_uploader(
â€œUpload Imagesâ€,
type=[â€˜jpgâ€™, â€˜jpegâ€™, â€˜pngâ€™],
accept_multiple_files=True
)

if uploaded_files:
st.success(fâ€ğŸ“ {len(uploaded_files)} files uploaded!â€)

```
if st.button("ğŸ” Process Images", type="primary"):
    progress = st.progress(0)
    
    for i, uploaded_file in enumerate(uploaded_files):
        try:
            # Load and process image
            image = Image.open(uploaded_file)
            image = ImageOps.exif_transpose(image)  # Fix orientation
            
            # Create unique key for this image
            image_key = make_image_key(uploaded_file.name, image)
            
            # Extract text
            original_text, processed_img, config = extract_text(image, enhancement_level)
            
            # Apply learned corrections
            corrected_text = apply_learned_corrections(original_text, image_key)
            
            # Store result
            result = {
                'filename': uploaded_file.name,
                'image_key': image_key,
                'original_text': original_text,
                'text': corrected_text,
                'config': config,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'image': image,
                'processed_image': processed_img
            }
            
            st.session_state.ocr_results.append(result)
            
        except Exception as e:
            st.error(f"Error processing {uploaded_file.name}: {e}")
        
        progress.progress((i + 1) / len(uploaded_files))
    
    st.success("âœ… Processing complete!")
```

# Display results

if st.session_state.ocr_results:
st.header(â€œğŸ“‹ Results & Learningâ€)

```
for i, result in enumerate(st.session_state.ocr_results):
    st.markdown("---")
    st.subheader(f"ğŸ“„ {result['filename']}")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.image(result['image'], caption="Original", use_container_width=True)
    
    with col2:
        # Show current result
        st.text_area(
            "Current OCR Result:",
            value=result['text'],
            height=100,
            disabled=True,
            key=f"current_{i}"
        )
        
        # Learning form
        with st.form(f"learn_{i}"):
            st.write("**Correct any mistakes and submit to improve future OCR:**")
            
            corrected_text = st.text_area(
                "Make corrections here:",
                value=result['text'],
                height=100,
                key=f"correct_{i}"
            )
            
            submitted = st.form_submit_button("ğŸ’¾ Save Correction & Learn")
            
            if submitted:
                if save_correction(result['image_key'], result['original_text'], corrected_text):
                    # Update the result
                    result['text'] = corrected_text
                    st.session_state.ocr_results[i] = result
                    
                    st.success("âœ… Correction saved and learned! Future OCR will be improved.")
                    st.rerun()
                else:
                    st.info("No changes detected.")
```

# Export section

if st.session_state.ocr_results:
st.header(â€œğŸ“¥ Exportâ€)

```
combined_text = "\n\n".join([
    f"FILE: {r['filename']}\nTIME: {r['timestamp']}\n\n{r['text']}"
    for r in st.session_state.ocr_results
])

st.download_button(
    "ğŸ“„ Download Text File",
    data=combined_text,
    file_name=f"ocr_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
    mime="text/plain"
)
```

# Corrections manager

if st.session_state.corrections:
st.header(â€œğŸ› ï¸ Saved Correctionsâ€)

```
for image_key, correction in st.session_state.corrections.items():
    with st.expander(f"Correction: {image_key}"):
        col1, col2 = st.columns(2)
        with col1:
            st.write("**Original:**")
            st.code(correction['original'])
        with col2:
            st.write("**Corrected:**")
            st.code(correction['corrected'])
        
        st.caption(f"Saved: {correction['timestamp']}")
        
        if st.button(f"ğŸ—‘ï¸ Delete", key=f"del_{image_key}"):
            del st.session_state.corrections[image_key]
            st.rerun()
```

# Debug section

if st.sidebar.checkbox(â€œShow Debug Infoâ€):
st.header(â€œğŸ Debug Infoâ€)
st.write(â€**Corrections:**â€, st.session_state.corrections)
st.write(â€**Learned Patterns:**â€, st.session_state.learned_patterns)
st.write(â€**Number of Results:**â€, len(st.session_state.ocr_results))

st.markdown(â€â€”â€)
st.markdown(â€*ğŸ’¡ Tip: The more corrections you make, the smarter the OCR becomes for your handwriting!*â€)
